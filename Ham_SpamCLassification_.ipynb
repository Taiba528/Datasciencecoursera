{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ham/SpamCLassification..ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taiba528/Datasciencecoursera/blob/master/Ham_SpamCLassification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drposuQGGSe8",
        "colab_type": "code",
        "outputId": "8cadd5c9-3209-43ff-fcc8-2cfceec1dc81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "#Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import collections\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, average_precision_score, recall_score\n",
        "import seaborn as sns\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity=\"all\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1x-gyhIGZum",
        "colab_type": "code",
        "outputId": "3445367a-6bcd-4885-ccd3-9d452e496f3e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b6bc1c27-a8e5-45a6-8a51-e7f6a7f230df\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b6bc1c27-a8e5-45a6-8a51-e7f6a7f230df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SMS-Messages2.csv to SMS-Messages2 (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jHvFdsaGjc9",
        "colab_type": "code",
        "outputId": "551697ac-07c7-486f-a49e-10a86cef461c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "df = pd.read_csv(\"SMS-Messages2.csv\")\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 266 entries, 0 to 265\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0    Message     266 non-null    object\n",
            " 1   Class_Label  202 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 4.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6ji8Er3lLc",
        "colab_type": "code",
        "outputId": "14726a4a-269a-4dbd-c3bd-0e7c1e37540f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "#explore the data\n",
        "df.shape\n",
        "df.size\n",
        "df.head()\n",
        "df.tail()\n",
        "type(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(266, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Class_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Go until jurong point</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Ok lar... Joking wif u oni...'</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Free entry in 2 a wkly comp to win FA Cup fin...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'U dun say so early hor... U c already then sa...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Nah I don\\'t think he goes to usf</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Message Class_Label\n",
              "0                             'Go until jurong point         ham\n",
              "1                    'Ok lar... Joking wif u oni...'         ham\n",
              "2  'Free entry in 2 a wkly comp to win FA Cup fin...        spam\n",
              "3  'U dun say so early hor... U c already then sa...         ham\n",
              "4                 'Nah I don\\'t think he goes to usf         ham"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Class_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>&lt;script src=\"https://reva.linkstreet.i...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>&lt;script src=\"https://reva.linkstreet.i...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>&lt;script src=\"https://reva.linkstreet.i...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>&lt;/body&gt;</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>&lt;/html&gt;</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Message Class_Label\n",
              "261          <script src=\"https://reva.linkstreet.i...         NaN\n",
              "262          <script src=\"https://reva.linkstreet.i...         NaN\n",
              "263          <script src=\"https://reva.linkstreet.i...         NaN\n",
              "264                                            </body>         NaN\n",
              "265                                            </html>         NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qYcDCTO6E9F",
        "colab_type": "code",
        "outputId": "855a6409-be2e-41fa-e7d3-cbc470dd7133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#check for missing values\n",
        "pd.isnull(df).any()\n",
        "pd.isnull(df).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Message       False\n",
              "Class_Label     True\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Message        0\n",
              "Class_Label    64\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rxP2dp45xRW",
        "colab_type": "code",
        "outputId": "ed8b0a0e-263f-436c-8ecb-53de6097411d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "df['Class_Label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham                     167\n",
              "spam                     33\n",
              " initial-scale=1.0\">      1\n",
              "chrome=1\">                1\n",
              "Name: Class_Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eOJNV1m32sJ",
        "colab_type": "code",
        "outputId": "ff919546-44cf-4413-a3e7-5a672b7da56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "#Visualize the number of ham and spam messages\n",
        "sns.countplot(df['Class_Label'])\n",
        "plt.xlabel('Label')\n",
        "plt.title('Number of ham and spam messages')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbde1d43fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Number of ham and spam messages')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgzRmyns4JJS",
        "colab_type": "code",
        "outputId": "f492f71d-890d-446b-c164-18b574ff9b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "#split the data in feature and labels\n",
        "X = df[' Message']\n",
        "Y = df['Class_Label']\n",
        "X.head()\n",
        "Y.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                               'Go until jurong point\n",
              "1                      'Ok lar... Joking wif u oni...'\n",
              "2    'Free entry in 2 a wkly comp to win FA Cup fin...\n",
              "3    'U dun say so early hor... U c already then sa...\n",
              "4                   'Nah I don\\'t think he goes to usf\n",
              "Name:  Message, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     ham\n",
              "1     ham\n",
              "2    spam\n",
              "3     ham\n",
              "4     ham\n",
              "Name: Class_Label, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxS52NsC5PJk",
        "colab_type": "code",
        "outputId": "d1eae8ed-c99e-4294-d907-0e2806dbf1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X)\n",
        "sequences = tok.texts_to_sequences(X)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-35f7e5373e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUOLACmlG33l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=df.iloc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltQoFTXL3d8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dummy coading using the loop structure\n",
        "for col in df.columns:\n",
        "    if df[col].dtype=='object':\n",
        "        df[col]=pd.Categorical( df[col]).codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJJCY3zG2SWP",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7lAaI5f2gZg",
        "colab_type": "text"
      },
      "source": [
        "## The first step in text analytics after reading the file is tokenization .It can be done at sentence level,word level or even character level.Here I am tokenizing it at word level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUkThoIp26ft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "f9f48cde-3d8d-438f-b724-691879872726"
      },
      "source": [
        "tokens = nltk.word_tokenize(X)\n",
        "print(\"Tokens : \",tokens[:20])\n",
        "print(\"\\n Total Tokens : \",len(tokens))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-b3637bad5700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokens : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Total Tokens : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m     94\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Standard word tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \"\"\"\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \"\"\"\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \"\"\"\n\u001b[1;32m   1315\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \"\"\"\n\u001b[1;32m    311\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCdILGWujPjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = []\n",
        "f_in = open(\"SMS-Messages2.csv\",'r')\n",
        "for line in f_in.readlines():\n",
        "    text.append(line)\n",
        "f_in.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsFAmd7s2mRR",
        "colab_type": "code",
        "outputId": "093c98b7-a1dc-4a7e-e335-b98a5f6f7e71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Message,Class_Label\\n',\n",
              " \"'Go until jurong point,ham\\n\",\n",
              " \"'Ok lar... Joking wif u oni...',ham\\n\",\n",
              " \"'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C\\\\'s apply 08452810075over18\\\\'s',spam\\n\",\n",
              " \"'U dun say so early hor... U c already then say...',ham\\n\",\n",
              " \"'Nah I don\\\\'t think he goes to usf,ham\\n\",\n",
              " \"'FreeMsg Hey there darling it\\\\'s been 3 week\\\\'s now and no word back! I\\\\'d like some fun you up for it still? Tb ok! XxX std chgs to send,spam\\n\",\n",
              " \"'Even my brother is not like to speak with me. They treat me like aids patent.',ham\\n\",\n",
              " \"'As per your request \\\\'Melle Melle (Oru Minnaminunginte Nurungu Vettam)\\\\' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune',ham\\n\",\n",
              " \"'WINNER!! As a valued network customer you have been selected to receivea 900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',spam\\n\",\n",
              " \"'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030',spam\\n\",\n",
              " \"'I\\\\'m gonna be home soon and i don\\\\'t want to talk about this stuff anymore tonight,ham\\n\",\n",
              " \"'SIX chances to win CASH! From 100 to 20,spam\\n\",\n",
              " \"'URGENT! You have won a 1 week FREE membership in our 100,spam\\n\",\n",
              " \"'I\\\\'ve been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.',ham\\n\",\n",
              " \"'I HAVE A DATE ON SUNDAY WITH WILL!!',ham\\n\",\n",
              " \"'XXXMobileMovieClub: To use your credit,spam\\n\",\n",
              " \"'Oh k...i\\\\'m watching here:)',ham\\n\",\n",
              " \"'Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.',ham\\n\",\n",
              " \"'Fine if that\\\\'s the way u feel. That\\\\'s the way its gota b',ham\\n\",\n",
              " \"'England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES,spam\\n\",\n",
              " \"'Is that seriously how you spell his name?',ham\\n\",\n",
              " \"'I\\\\'m going to try for 2 months ha ha only joking',ham\\n\",\n",
              " \"'So  pay first lar... Then when is da stock comin...',ham\\n\",\n",
              " \"'Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?',ham\\n\",\n",
              " \"'Ffffffffff. Alright no way I can meet up with you sooner?',ham\\n\",\n",
              " \"'Just forced myself to eat a slice. I\\\\'m really not hungry tho. This sucks. Mark is getting worried. He knows I\\\\'m sick when I turn down pizza. Lol',ham\\n\",\n",
              " \"'Lol your always so convincing.',ham\\n\",\n",
              " \"'Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom\\\\'s left over dinner ? Do you feel my Love ?',ham\\n\",\n",
              " \"'I\\\\'m back &amp; we\\\\'re packing the car now,ham\\n\",\n",
              " \"'Ahhh. Work. I vaguely remember that! What does it feel like? Lol',ham\\n\",\n",
              " \"'Wait that\\\\'s still not all that clear,ham\\n\",\n",
              " \"'Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won\\\\'t go there! Not doing too badly cheers. You? ,ham\\n\",\n",
              " \"'K tell me anything about you.',ham\\n\",\n",
              " \"'For fear of fainting with the of all that housework you just did? Quick have a cuppa',ham\\n\",\n",
              " \"'Thanks for your subscription to Ringtone UK your mobile will be charged 5/month Please confirm by replying YES or NO. If you reply NO you will not be charged',spam\\n\",\n",
              " \"'Yup... Ok i go home look at the timings then i msg  again... Xuhui going to learn on 2nd may too but her lesson is at 8am',ham\\n\",\n",
              " \"'Oops,ham\\n\",\n",
              " \"'I see the letter B on my car',ham\\n\",\n",
              " \"'Anything lor... U decide...',ham\\n\",\n",
              " \"'Hello! How\\\\'s you and how did saturday go? I was just texting to see if you\\\\'d decided to do anything tomo. Not that i\\\\'m trying to invite myself or anything!',ham\\n\",\n",
              " \"'Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola',ham\\n\",\n",
              " \"'Did I forget to tell you ? I want you ,ham\\n\",\n",
              " \"'07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow',spam\\n\",\n",
              " \"'WHO ARE YOU SEEING?',ham\\n\",\n",
              " \"'Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches...',ham\\n\",\n",
              " \"'No calls..messages..missed calls',ham\\n\",\n",
              " \"'Didn\\\\'t you get hep b immunisation in nigeria.',ham\\n\",\n",
              " \"'Fair enough,ham\\n\",\n",
              " \"'Yeah hopefully,ham\\n\",\n",
              " \"'U don\\\\'t know how stubborn I am. I didn\\\\'t even want to go to the hospital. I kept telling Mark I\\\\'m not a weak sucker. Hospitals are for weak suckers.',ham\\n\",\n",
              " \"'What you thinked about me. First time you saw me in class.',ham\\n\",\n",
              " \"'A gram usually runs like  &lt;#&gt; ,ham\\n\",\n",
              " \"'K fyi x has a ride early tomorrow morning but he\\\\'s crashing at our place tonight',ham\\n\",\n",
              " \"'Wow. I never realized that you were so embarassed by your accomodations. I thought you liked it,ham\\n\",\n",
              " \"'SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV',spam\\n\",\n",
              " \"'Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;',ham\\n\",\n",
              " \"'Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V,spam\\n\",\n",
              " \"'Sorry,ham\\n\",\n",
              " \"'Tell where you reached',ham\\n\",\n",
              " \"'Yes..gauti and sehwag out of odi series.',ham\\n\",\n",
              " \"'Your gonna have to pick up a $1 burger for yourself on your way home. I can\\\\'t even move. Pain is killing me.',ham\\n\",\n",
              " \"'Ha ha ha good joke. Girls are situation seekers.',ham\\n\",\n",
              " \"'Its a part of checking IQ',ham\\n\",\n",
              " \"'Sorry my roommates took forever,ham\\n\",\n",
              " \"'Ok lar i double check wif da hair dresser already he said wun cut v short. He said will cut until i look nice.',ham\\n\",\n",
              " \"'As a valued customer,spam\\n\",\n",
              " '\"\\'Today is \"\"song dedicated day..\"\" Which song will u dedicate for me? Send this to all ur valuable frnds but first rply me...\\'\",ham\\n',\n",
              " \"'Urgent UR awarded a complimentary trip to EuroDisinc Trav,spam\\n\",\n",
              " '\"\\'Did you hear about the new \"\"Divorce Barbie\"\"? It comes with all of Ken\\\\\\'s stuff!\\'\",spam\\n',\n",
              " \"'I plane to give on this month end.',ham\\n\",\n",
              " \"'Wah lucky man... Then can save money... Hee...',ham\\n\",\n",
              " \"'Finished class where are you.',ham\\n\",\n",
              " \"'HI BABE IM AT HOME NOW WANNA DO SOMETHING? XX',ham\\n\",\n",
              " \"'K..k:)where are you?how did you performed?',ham\\n\",\n",
              " \"'U can call me now...',ham\\n\",\n",
              " \"'I am waiting machan. Call me once you free.',ham\\n\",\n",
              " \"'Thats cool. i am a gentleman and will treat you with dignity and respect.',ham\\n\",\n",
              " \"'I like you peoples very much:) but am very shy pa.',ham\\n\",\n",
              " \"'Does not operate after  &lt;#&gt;  or what',ham\\n\",\n",
              " \"'Its not the same here. Still looking for a job. How much do Ta\\\\'s earn there.',ham\\n\",\n",
              " \"'Sorry,ham\\n\",\n",
              " \"'K. Did you call me just now ah? ,ham\\n\",\n",
              " \"'Ok i am on the way to home hi hi',ham\\n\",\n",
              " \"'You will be in the place of that man',ham\\n\",\n",
              " \"'Yup next stop.',ham\\n\",\n",
              " \"'I call you later,ham\\n\",\n",
              " \"'For real when u getting on yo? I only need 2 more tickets and one more jacket and I\\\\'m done. I already used all my multis.',ham\\n\",\n",
              " \"'Yes I started to send requests to make it but pain came back so I\\\\'m back in bed. Double coins at the factory too. I gotta cash in all my nitros.',ham\\n\",\n",
              " \"'I\\\\'m really not up to it still tonight babe',ham\\n\",\n",
              " \"'Ela kano.,ham\\n\",\n",
              " \"'Yeah do! Don\\\\'t stand to close tho- you\\\\'ll catch something!',ham\\n\",\n",
              " \"'Sorry to be a pain. Is it ok if we meet another night? I spent late afternoon in casualty and that means i haven\\\\'t done any of y stuff42moro and that includes all my time sheets and that. Sorry. ,ham\\n\",\n",
              " \"'Smile in Pleasure Smile in Pain Smile when trouble pours like Rain Smile when sum1 Hurts U Smile becoz SOMEONE still Loves to see u Smiling!!',ham\\n\",\n",
              " \"'Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a guaranteed 1000 cash or 5000 prize!',spam\\n\",\n",
              " \"'Havent planning to buy later. I check already lido only got 530 show in e afternoon. U finish work already?',ham\\n\",\n",
              " '\"\\'Your free ringtone is waiting to be collected. Simply text the password \"\"MIX\"\" to 85069 to verify. Get Usher and Britney. FML\",spam\\n',\n",
              " \"'Watching telugu movie..wat abt u?',ham\\n\",\n",
              " \"'i see. When we finish we have loads of loans to pay',ham\\n\",\n",
              " '\"\\'Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appointment at four so need to get home n shower beforehand. Does that cause prob for u?\"\"\",ham\\n',\n",
              " \"'I see a cup of coffee animation',ham\\n\",\n",
              " \"'Please don\\\\'t text me anymore. I have nothing else to say.',ham\\n\",\n",
              " \"'Okay name ur price as long as its legal! Wen can I pick them up? Y u ave x ams xx',ham\\n\",\n",
              " \"'I\\\\'m still looking for a car to buy. And have not gone 4the driving test yet.',ham\\n\",\n",
              " \"'As per your request \\\\'Melle Melle (Oru Minnaminunginte Nurungu Vettam)\\\\' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune',ham\\n\",\n",
              " \"'wow. You\\\\'re right! I didn\\\\'t mean to do that. I guess once i gave up on boston men and changed my search location to nyc,ham\\n\",\n",
              " \"'Umma my life and vava umma love you lot dear',ham\\n\",\n",
              " \"'Thanks a lot for your wishes on my birthday. Thanks you for making my birthday truly memorable.',ham\\n\",\n",
              " \"'Aight,ham\\n\",\n",
              " \"'How would my ip address test that considering my computer isn\\\\'t a minecraft server',ham\\n\",\n",
              " \"'I know! Grumpy old people. My mom was like you better not be lying. Then again I am always the one to play jokes...',ham\\n\",\n",
              " \"'Dont worry. I guess he\\\\'s busy.',ham\\n\",\n",
              " \"'What is the plural of the noun research?',ham\\n\",\n",
              " \"'Going for dinner.msg you after.',ham\\n\",\n",
              " \"'I\\\\'m ok wif it cos i like 2 try new things. But i scared u dun like mah. Cos u said not too loud.',ham\\n\",\n",
              " \"'GENT! We are trying to contact you. Last weekends draw shows that you won a 1000 prize GUARANTEED. Call 09064012160. Claim Code K52. Valid 12hrs only. 150ppm',spam\\n\",\n",
              " \"'Wa,ham\\n\",\n",
              " \"'As I entered my cabin my PA said,ham\\n\",\n",
              " \"'You are a winner U have been specially selected 2 receive 1000 or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810910p/min (18+) ,spam\\n\",\n",
              " \"'Goodo! Yes we must speak friday - egg-potato ratio for tortilla needed! ,ham\\n\",\n",
              " \"'Hmm...my uncle just informed me that he\\\\'s paying the school directly. So pls buy food.',ham\\n\",\n",
              " \"'PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim call 08719180248 Identifier Code: 45239 Expires',spam\\n\",\n",
              " \"'URGENT! Your Mobile No. was awarded 2000 Bonus Caller Prize on 5/9/03 This is our final try to contact U! Call from Landline 09064019788 BOX42WR29C,spam\\n\",\n",
              " \"'here is my new address -apples&pairs&all that malarky',ham\\n\",\n",
              " \"'Todays Voda numbers ending 7548 are selected to receive a $350 award. If you have a match please call 08712300220 quoting claim code 4041 standard rates app',spam\\n\",\n",
              " \"'I am going to sao mu today. Will be done only at 12 ,ham\\n\",\n",
              " \"' predict wat time \\\\'ll finish buying?',ham\\n\",\n",
              " \"'Good stuff,ham\\n\",\n",
              " \"'Just so that you know,ham\\n\",\n",
              " \"'Are you there in room.',ham\\n\",\n",
              " \"'HEY GIRL. HOW R U? HOPE U R WELL ME AN DEL R BAK! AGAIN LONG TIME NO C! GIVE ME A CALL SUM TIME FROM LUCYxx',ham\\n\",\n",
              " \"'K..k:)how much does it cost?',ham\\n\",\n",
              " \"'I\\\\'m home.',ham\\n\",\n",
              " \"'Dear,ham\\n\",\n",
              " \"'First answer my question.',ham\\n\",\n",
              " \"'Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country the Algarve is in? Txt ansr to 82277. 1.50 SP:Tyrone',spam\\n\",\n",
              " \"'Want 2 get laid tonight? Want real Dogging locations sent direct 2 ur mob? Join the UK\\\\'s largest Dogging Network bt Txting GRAVEL to 69888! Nt. ec2a. 31p.msg@150p',spam\\n\",\n",
              " \"'I only haf msn. It\\\\'s yijue@hotmail.com',ham\\n\",\n",
              " \"'He is there. You call and meet him',ham\\n\",\n",
              " \"'No no. I will check all rooms befor activities',ham\\n\",\n",
              " \"'You\\\\'ll not rcv any more msgs from the chat svc. For FREE Hardcore services text GO to: 69988 If u get nothing u must Age Verify with yr network & try again',spam\\n\",\n",
              " \"'Got c... I lazy to type... I forgot  in lect... I saw a pouch but like not v nice...',ham\\n\",\n",
              " \"'K,ham\\n\",\n",
              " \"'Sir,ham\\n\",\n",
              " '\"\\'A swt thought: \"\"Nver get tired of doing little things 4 lovable persons..\"\" Coz..somtimes those little things occupy d biggest part in their Hearts.. Gud ni8\\'\",ham\\n',\n",
              " \"'I know you are. Can you pls open the back?',ham\\n\",\n",
              " \"'Yes see ya not on the dot',ham\\n\",\n",
              " \"'Whats the staff name who is taking class for us?',ham\\n\",\n",
              " \"'FreeMsg Why haven\\\\'t you replied to my text? I\\\\'m Randy,spam\\n\",\n",
              " \"'Ummma.will call after check in.our life will begin from qatar so pls pray very hard.',ham\\n\",\n",
              " \"'K..i deleted my contact that why?',ham\\n\",\n",
              " \"'Sindu got job in birla soft ..',ham\\n\",\n",
              " \"'The wine is flowing and i\\\\'m i have nevering..',ham\\n\",\n",
              " \"'Yup i thk cine is better cos no need 2 go down 2 plaza mah.',ham\\n\",\n",
              " \"'Ok... Ur typical reply...',ham\\n\",\n",
              " \"'As per your request \\\\'Melle Melle (Oru Minnaminunginte Nurungu Vettam)\\\\' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune',ham\\n\",\n",
              " \"'You are everywhere dirt,ham\\n\",\n",
              " \"'Aaooooright are you at work?',ham\\n\",\n",
              " \"'I\\\\'m leaving my house now...',ham\\n\",\n",
              " \"'Hello,ham\\n\",\n",
              " \"'Customer service annoncement. You have a New Years delivery waiting for you. Please call 07046744435 now to arrange delivery',spam\\n\",\n",
              " \"'You are a winner U have been specially selected 2 receive 1000 cash or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810810',spam\\n\",\n",
              " \"'Keep yourself safe for me because I need you and I miss you already and I envy everyone that see\\\\'s you in real life',ham\\n\",\n",
              " \"'New car and house for my parents.:)i have only new job in hand:)',ham\\n\",\n",
              " \"'I\\\\'m so in love with you. I\\\\'m excited each day i spend with you. You make me so happy.',ham\\n\",\n",
              " \"'-PLS STOP bootydelious (32/F) is inviting you to be her friend. Reply YES-434 or NO-434 See her: www.SMS.ac/u/bootydelious STOP? Send STOP FRND to 62468',spam\\n\",\n",
              " \"'BangBabes Ur order is on the way. U SHOULD receive a Service Msg 2 download UR content. If U do not,spam\\n\",\n",
              " \"'I place all ur points on e cultures module already.',ham\\n\",\n",
              " \"'URGENT! We are trying to contact you. Last weekends draw shows that you have won a 900 prize GUARANTEED. Call 09061701939. Claim code S89. Valid 12hrs only',spam\\n\",\n",
              " \"'Hi frnd,ham\\n\",\n",
              " \"'Great escape. I fancy the bridge but needs her lager. See you tomo ,ham\\n\",\n",
              " \"'Yes :)it completely in out of form:)clark also utter waste.',ham\\n\",\n",
              " \"'Sir,ham\\n\",\n",
              " \"'Hmmm.. Thk sure got time to hop ard... Ya,ham\\n\",\n",
              " \"'What time you coming down later? ,ham\\n\",\n",
              " \"'Bloody hell,ham\\n\",\n",
              " \"'Well,ham\\n\",\n",
              " \"'Let me know when you\\\\'ve got the money so carlos can make the call',ham\\n\",\n",
              " \"'U still going to the mall?',ham\\n\",\n",
              " \"'Turns out my friends are staying for the whole show and won\\\\'t be back til ~ &lt;#&gt; ,ham\\n\",\n",
              " \"'Text her. If she doesnt reply let me know so i can have her log in',ham\\n\",\n",
              " \"'Hi! You just spoke to MANEESHA V. We\\\\'d like to know if you were satisfied with the experience. Reply Toll Free with Yes or No.',ham\\n\",\n",
              " \"'You lifted my hopes with the offer of money. I am in need. Especially when the end of the month approaches and it hurts my studying. Anyways have a gr8 weekend',ham\\n\",\n",
              " \"'Lol no. U can trust me.',ham\\n\",\n",
              " \"'ok. I am a gentleman and will treat you with dignity and respect.',ham\\n\",\n",
              " \"'He will,ham\\n\",\n",
              " \"'Going on nothing great.bye',ham\\n\",\n",
              " \"'Hello handsome ! Are you finding that job ? Not being lazy ? Working towards getting back that net for mummy ? Where\\\\'s my boytoy now ? Does he miss me ?',ham\\n\",\n",
              " \"'Haha awesome,ham\\n\",\n",
              " \"'Please call our customer service representative on FREEPHONE 0808 145 4742 between 9am-11pm as you have WON a guaranteed 1000 cash or 5000 prize!',spam\\n\",\n",
              " \"'Have you got Xmas radio times. If not i will get it now',ham\\n\",\n",
              " \"'I jus reached home. I go bathe first. But my sis using net tell u when she finishes k...',ham\\n\",\n",
              " \"'Are you unique enough? Find out from 30th August. www.areyouunique.co.uk',spam\\n\",\n",
              " \"'I\\\\'m sorry. I\\\\'ve joined the league of people that dont keep in touch. You mean a great deal to me. You have been a friend at all times even at great personal cost. Do have a great week.|',ham\\n\",\n",
              " \"'Hi :)finally i completed the course:)',ham\\n\",\n",
              " \"'It will stop on itself. I however suggest she stays with someone that will be able to give ors for every stool.',ham\\n\",\n",
              " \"'How are you doing? Hope you\\\\'ve settled in for the new school year. Just wishin you a gr8 day',ham\\n\",\n",
              " \"'Gud mrng dear hav a nice day',ham\\n\",\n",
              " \"'Did u got that persons story',ham\\n\",\n",
              " \"'is your hamster dead? Hey so tmr i meet you at 1pm orchard mrt? ,ham\\n\",\n",
              " \"'Hi its Kate how is your evening? I hope i can see you tomorrow for a bit but i have to bloody babyjontet! Txt back if u can. :) xxx',ham\\n\",\n",
              " '<!DOCTYPE html>\\n',\n",
              " '<html>\\n',\n",
              " '    <head>\\n',\n",
              " '        <meta charset=\"utf-8\">\\n',\n",
              " '        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n',\n",
              " '        <title>Download document</title>\\n',\n",
              " '        <meta name=\"description\" content=\"\">\\n',\n",
              " '        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n',\n",
              " '\\n',\n",
              " '        <!-- Place favicon.ico and apple-touch-icon.png in the root directory -->\\n',\n",
              " '\\n',\n",
              " '        <!--base css styles-->\\n',\n",
              " '        <link rel=\"stylesheet\" href=\"https://reva.linkstreet.in/admin/assets/bootstrap/css/bootstrap.min.css\">\\n',\n",
              " '        <link rel=\"stylesheet\" href=\"https://reva.linkstreet.in/admin/assets/bootstrap-datepicker/css/bootstrap-datepicker.min.css\">\\n',\n",
              " '        <link rel=\"stylesheet\" href=\"https://reva.linkstreet.in/admin/assets/font-awesome/css/font-awesome.min.css\">\\n',\n",
              " '\\n',\n",
              " '        <!--page specific css styles-->\\n',\n",
              " '\\n',\n",
              " '        <!--flaty css styles-->\\n',\n",
              " '        <link rel=\"stylesheet\" href=\"https://reva.linkstreet.in/admin/css/flaty.css\">\\n',\n",
              " '        <link rel=\"stylesheet\" href=\"https://reva.linkstreet.in/admin/css/flaty-responsive.css\">\\n',\n",
              " '        <link rel=\"stylesheet\" href=\"https://reva.linkstreet.in/admin/assets/dropzone/downloads/css/basic.css\">\\n',\n",
              " '        <link rel=\"stylesheet\" href=\"https://reva.linkstreet.in/admin/assets/dropzone/downloads/css/dropzone.css\">\\n',\n",
              " '        <link rel=\"stylesheet\" type=\"text/css\" href=\"https://reva.linkstreet.in/admin/assets/bootstrap-fileupload/bootstrap-fileupload.css\" />\\n',\n",
              " '        <link rel=\"stylesheet\" type=\"text/css\" href=\"https://reva.linkstreet.in/admin/css/customcss.css?version=0.0.1\" />\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '        <link rel=\"shortcut icon\" href=\"https://reva.linkstreet.in/admin/img/favicon.ico\">\\n',\n",
              " '\\n',\n",
              " '        <script src=\"//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\\n',\n",
              " '        <script>window.jQuery || document.write(\\'<script src=\"https://reva.linkstreet.in/admin/assets/jquery/jquery-2.1.1.min.js\"><\\\\/script>\\')</script>\\n',\n",
              " '    </head>\\n',\n",
              " '    <body class=\"skin\">\\n',\n",
              " '                <div class=\"container\" id=\"main-container\">\\n',\n",
              " '            \\t\\t\\t<div id=\"main-content\">\\n',\n",
              " '\\t\\t\\t\\t\\t\\t\\t\\t<!-- End Breadcrumbs -->\\n',\n",
              " '\\t\\t\\t\\t<!-- BEGIN Page Title -->\\n',\n",
              " '                \\t\\t\\t\\t<div class=\"page-title\">\\n',\n",
              " '\\t\\t\\t\\t\\t<div>\\n',\n",
              " '\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<h1><i class=\"fa fa-download\"></i> Download document</h1>\\n',\n",
              " '\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n',\n",
              " '\\t\\t\\t\\t</div>\\n',\n",
              " '                \\t\\t\\t\\t<!-- END Page Title -->\\n',\n",
              " '\\n',\n",
              " '\\t\\t\\t\\t<!-- BEGIN Breadcrumb -->\\n',\n",
              " '\\t\\t\\t\\t\\t\\t\\t\\t<!-- END Breadcrumb -->\\n',\n",
              " '\\n',\n",
              " '\\t\\t\\t\\t<!-- BEGIN Main Content -->\\n',\n",
              " '                <!--  -->\\n',\n",
              " '\\t\\t\\t\\t\\t\\t\\t\\t<!-- END Main Content -->\\n',\n",
              " '\\n',\n",
              " '\\t\\t\\t\\t<!-- BEGIN Footer -->\\n',\n",
              " '\\t\\t\\t\\t\\t\\t\\t\\t<!-- END Footer -->\\n',\n",
              " '\\n',\n",
              " '\\t\\t\\t\\t<a id=\"btn-scrollup\" class=\"btn btn-circle btn-lg\" href=\"#\"><i class=\"fa fa-arrow-up\"></i></a>\\n',\n",
              " '\\t\\t\\t</div>\\n',\n",
              " '        </div>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/bootstrap/js/bootstrap.min.js\"></script>\\n',\n",
              " '         <script src=\"https://reva.linkstreet.in/admin/assets/bootstrap-datepicker/js/bootstrap-datepicker.min.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/jquery-slimscroll/jquery.slimscroll.min.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/jquery-cookie/jquery.cookie.js\"></script>\\n',\n",
              " '\\n',\n",
              " '        <!--page specific plugin scripts-->\\n',\n",
              " '\\n',\n",
              " '\\t\\t<script src=\"https://reva.linkstreet.in/admin/assets/bootstrap-fileupload/bootstrap-fileupload.min.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/flot/jquery.flot.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/flot/jquery.flot.resize.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/flot/jquery.flot.pie.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/flot/jquery.flot.stack.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/flot/jquery.flot.crosshair.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/flot/jquery.flot.tooltip.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/dropzone/downloads/dropzone.min.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/assets/sparkline/jquery.sparkline.min.js\"></script>\\n',\n",
              " '\\n',\n",
              " '        <!--flaty scripts-->\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/js/flaty.js\"></script>\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/js/flaty-demo-codes.js\"></script>\\n',\n",
              " '\\n',\n",
              " '        <script src=\"https://reva.linkstreet.in/admin/js/footerjs.js?version=2.0.4\"></script>\\n',\n",
              " '\\n',\n",
              " '    </body>\\n',\n",
              " '</html>\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXw9nlRajPt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [] #Create an empty corpus\n",
        "ps = PorterStemmer() # For Stemming the words to original form\n",
        "stop_words = set(stopwords.words('english')) # removes words like will, i, and, it etc\n",
        "for i in range(1,2000):\n",
        "  \n",
        "  # Convert all words to lower case\n",
        "  text_cln = text_cln.lower()\n",
        "  # Split sentences in to words\n",
        "  text_cln = text_cln.split()\n",
        "  # Remove english stopwords\n",
        "  text_cln = [x for x in text_cln if not x in stop_words]\n",
        "  # Lemmatize words to the base form\n",
        "  wn = nltk.WordNetLemmatizer()\n",
        "  text_cln = [wn.lemmatize(x) for x in text_cln]\n",
        "  # Join words to form the original sentence, but cleaned-up\n",
        "  text_cln = \" \".join(text_cln)\n",
        "  #Append to the list to get all the tweets in one place\n",
        "  corpus.append(text_cln)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZsAKUAIjegl",
        "colab_type": "code",
        "outputId": "14def5ad-5984-4215-9d38-5645a1bb95ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Clean Corpus\n",
        "corpus[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['html', 'html', 'html', 'html', 'html']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wivOc--0jnb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Strip the records and create a word list for each text\n",
        "word_list = []\n",
        "for record in (corpus):\n",
        "    #print(record)\n",
        "    words = []\n",
        "    tokens = record.split()\n",
        "    #print(tokens)\n",
        "    for token in tokens:\n",
        "        words.append(token.lower())\n",
        "    word_list.append(words)  \n",
        "    \n",
        "word_list "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0jxe2SjGvBH",
        "colab_type": "text"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlq56u5MG5Uw",
        "colab_type": "text"
      },
      "source": [
        "#Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--LzJ0OrHGOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Explore Data\n",
        "df.shape\n",
        "type(df)\n",
        "df.size\n",
        "df.shape\n",
        "df.head()\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C42nJonLHS-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Star_Ratings.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vguZJMbfHfCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_size = plt.rcParams[\"figure.figsize\"] \n",
        "plot_size[0] = 8\n",
        "plot_size[1] = 6\n",
        "plt.rcParams[\"figure.figsize\"] = plot_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DKlh8-GHm6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Star_Ratings.value_counts().plot(kind='bar', color=[\"green\",\"olive\",\"yellow\",\"orange\",\"red\"],)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HOz7YjIHbRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Ratings_category'] = df['Star_Ratings'].apply(lambda Ratings: 'positive' if Ratings > 3 else 'negative')\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy7uWksulLz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Ratings_category.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRSOhHt-JFcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Ratings_category.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=[\"green\", \"red\",])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc_9v2sCZRst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_positive=df[df['Ratings_category'] == 'positive']\n",
        "df_negative=df[df['Ratings_category']=='negative']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r83KAM0GY5--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Reviews_all=\" \".join(review for review in df.Ratings_category)\n",
        "Reviews_positive=\" \".join(review for review in df_positive.Reviews)\n",
        "Reviews_negative=\" \".join(review for review in df_negative.Reviews)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p7xYw8ae8p2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
        "fig, ax = plt.subplots(3, 1, figsize  = (20,20))\n",
        "#wordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweets)\n",
        "wordcloud_positive = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(Reviews_positive)\n",
        "wordcloud_negative = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(Reviews_negative)\n",
        "# Display the generated image:\n",
        "ax[0].imshow(wordcloud_positive, interpolation='bilinear')\n",
        "ax[0].set_title('Positive Reviews', fontsize=20)\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(wordcloud_negative, interpolation='bilinear')\n",
        "ax[1].set_title('Negative Reviews',fontsize=20)\n",
        "ax[1].axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgUO09KzHoIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_list = []\n",
        "\n",
        "max = len(df.Reviews)\n",
        "for i in range (max):\n",
        "  R1= df.Reviews[i]\n",
        "  tokens = R1.split()\n",
        "  #print(tokens)\n",
        "  words = []\n",
        "  \n",
        "  for token in tokens:\n",
        "    words.append(token.lower())\n",
        "  word_list.append(words) \n",
        "print(len(word_list))\n",
        "word_list[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPGo0pDhIbP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxg-A_OPIbVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lex_file = open(\"AFINN-111.csv\",encoding='cp1252')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHW1CB4LIbZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lexicons = {}\n",
        "records = lex_file.readlines()\n",
        "for record in records:\n",
        "    #print(record) # line contains newline charecter\n",
        "    #print(record.rstrip('\\n').split(\",\")) - to remove new line charecter\n",
        "    lexicons[record.rstrip('\\n').split(\",\")[0]] = int(record.rstrip('\\n').split(\",\")[1])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZQ0Ub1PI5Oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For each word in text\n",
        "#Get the word score (score is a number if the word is in Lexicon, 0 if not)\n",
        "#Add all the scores and find the ploarity\n",
        "sentiment_score = []\n",
        "for text in word_list:\n",
        "    score = 0\n",
        "    for word in text:\n",
        "        if word in (lexicons):\n",
        "            score = int(score + lexicons[word])\n",
        "    sentiment_score.append(score)\n",
        "sentiment_score[5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko0vbIarIbbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['sentiment_score'] = sentiment_score\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io3fR-x9JFMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Pred_Ratings_category'] = df['sentiment_score'].apply(lambda sentiment_score: 'positive' if sentiment_score > 0 else 'negative')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCeo-z2lk7kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('IIMB.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg1rA4OUqx3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Pred_Ratings_category.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZktBFpZBGA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Pred_Ratings_category.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=[\"green\", \"red\",])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWwexLDEpBri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(df['Ratings_category'],df['Pred_Ratings_category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h6WwLXbIbqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_1 = df[['Reviews','sentiment_score','Star_Ratings']]\n",
        "df_1.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyYJCdHL43p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_1.to_csv('IIMB_F.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_2H0wkD9EZs",
        "colab_type": "text"
      },
      "source": [
        "## Creating Labels and Features to apply ML models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFOPe0mUJu2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df_1['Reviews']\n",
        "x.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3chT_j5J0Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df_1.iloc[:, -1]\n",
        "y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcopdMDILl3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the Bag of Words model \n",
        "from sklearn.feature_extraction.text import CountVectorizer "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wAM2hV5MzH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To extract max 1500 feature. \n",
        "# \"max_features\" is attribute to \n",
        "# experiment with to get better results \n",
        "cv = CountVectorizer(max_features = 1500)  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoh_CTAlPzWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = cv.fit_transform(x).toarray()  \n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epdi0PRhJ9n1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1UnHiaWKA5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape\n",
        "X_test.shape\n",
        "y_train.shape\n",
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6cvyEYNJXSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Linear Regression Model\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUL3dZZRJaKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm = LinearRegression()\n",
        "lm = lm.fit(x,y)\n",
        "coefficients = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(lm.coef_))], axis = 1)\n",
        "coefficients\n",
        "lm.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXdAeVpN9Wcc",
        "colab_type": "text"
      },
      "source": [
        "# KNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYAAFNxCKFKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN models with only 1 neighbour\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=1)\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNb3GjFWrMHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxCCWsgbrRZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB0HQz2Ppq53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 5\n",
        "for i in range(1, 5):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))\n",
        "    print(error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0DzzX75tKT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7oh85WPtV9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape\n",
        "X_test.shape\n",
        "y_train.shape\n",
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rRbd8qmtha9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=2)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M9_z5Urthe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOSX3saothg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l4XclZbthZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 5\n",
        "for i in range(1, 5):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))\n",
        "    print(error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0F3Ho_Fua2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRueA-BDujs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape\n",
        "X_test.shape\n",
        "y_train.shape\n",
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8MSQQzxuznt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9i2UeA7vMAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I8Gbd7MvTCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsVjaWCGvd7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 5\n",
        "for i in range(1, 5):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))\n",
        "    print(error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyCdP-q0vt9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1evz8PLpv3s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape\n",
        "X_test.shape\n",
        "y_train.shape\n",
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpOcnDJvwEKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdUU7KQOwWyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w70-lemYwgMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fB7BRQMwxC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 5\n",
        "for i in range(1, 5):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))\n",
        "    print(error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzAwNDmXPkuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 40\n",
        "for i in range(1, 40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVW5TsXROmHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsx1jJb1SjQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRpgXa5-R6Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=9)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8oZIJJZSEYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9WE73KJSNbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAz4sKi1Atqw",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2spJlK8KAuAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e59VwbTgM-w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Fitting Random Forest Classification \n",
        "# to the Training set \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "  \n",
        "# n_estimators can be said as number of \n",
        "# trees, experiment with n_estimators \n",
        "# to get better results  \n",
        "model = RandomForestClassifier(n_estimators = 501, \n",
        "                            criterion = 'entropy') \n",
        "                              \n",
        "model.fit(X_train, y_train) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keCNXcfSJPHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting the Test set results \n",
        "y_pred = model.predict(X_test)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rZT9W-AxCsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjzg926xXGgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
        "fig, ax = plt.subplots(3, 1, figsize  = (20,20))\n",
        "# Create and generate a word cloud image:\n",
        "df_new_positive=df[df['Ratings_category'] == 'positive']\n",
        "df_new_negative=df[df['Ratings_category']=='negative']\n",
        "tweet_all=\" \".join(review for review in df.Tweet)\n",
        "tweet_positive=\" \".join(review for review in df_positive.Tweet)\n",
        "tweet_negative=\" \".join(review for review in df_negative.Tweet)\n",
        "tweet_neutral=\" \".join(review for review in df_neutral.Tweet)\n",
        "#wordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweets)\n",
        "wordcloud_positive = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_positive)\n",
        "wordcloud_negative = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_negative)\n",
        "wordcloud_neutral = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_neutral)\n",
        "# Display the generated image:\n",
        "ax[0].imshow(wordcloud_positive, interpolation='bilinear')\n",
        "ax[0].set_title('Positive Tweets', fontsize=30)\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(wordcloud_negative, interpolation='bilinear')\n",
        "ax[1].set_title('Negative Tweets',fontsize=30)\n",
        "ax[1].axis('off')\n",
        "ax[2].imshow(wordcloud_neutral, interpolation='bilinear')\n",
        "ax[2].set_title('Neutral Tweets',fontsize=30)\n",
        "ax[2].axis('off')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mj0_OmSXyYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_neutral=df[df['Ratings_category']=='neutral']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPiwce3Zkp1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = []\n",
        "f_in = open(\"Amazon Reviews with Ratings.csv\",'r')\n",
        "for line in f_in.readlines():\n",
        "    text.append(line)\n",
        "f_in.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFGUXAYtItRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [] #Create an empty corpus\n",
        "ps = PorterStemmer() # For Stemming the words to original form\n",
        "stop_words = set(stopwords.words('english')) # removes words like will, i, and, it etc\n",
        "for i in range(1,2000):\n",
        "  #removes handles (@), numbers, urls emojis and any other special charcters to have only text\n",
        "  text_cln = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|[0-9]\", ' ',text[i])\n",
        "  # Convert all words to lower case\n",
        "  text_cln = text_cln.lower()\n",
        "  # Split sentences in to words\n",
        "  text_cln = text_cln.split()\n",
        "  # Remove english stopwords\n",
        "  text_cln = [x for x in text_cln if not x in stop_words]\n",
        "  # Lemmatize words to the base form\n",
        "  wn = nltk.WordNetLemmatizer()\n",
        "  text_cln = [wn.lemmatize(x) for x in text_cln]\n",
        "  # Join words to form the original sentence, but cleaned-up\n",
        "  text_cln = \" \".join(text_cln)\n",
        "  #Append to the list to get all the tweets in one place\n",
        "  corpus.append(text_cln)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2O8DfquJX7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clean Corpus\n",
        "corpus[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8CHjKlcFw5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Strip the records and create a word list for each text\n",
        "word_list = []\n",
        "for record in (corpus):\n",
        "    #print(record)\n",
        "    words = []\n",
        "    tokens = record.split()\n",
        "    #print(tokens)\n",
        "    for token in tokens:\n",
        "        words.append(token.lower())\n",
        "    word_list.append(words)  \n",
        "    \n",
        "word_list "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PvCALti2096",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(word_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIYa0R_V67JH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_word_list = []\n",
        "for word in word_list:\n",
        "    if(word in words_remove):\n",
        "        pass\n",
        "else:\n",
        "    new_word_list.append(word)\n",
        "    print(new_word_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x7NXRKGJ35f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bagofwords = []\n",
        "for i in range(1,1999):\n",
        "  words = corpus[i].split()\n",
        "  bagofwords.append(words)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WTCb81tJ80p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bagofwords[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDGM9be4KHBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words = list(itertools.chain(*bagofwords))\n",
        "print(all_words[0:10])\n",
        "print()\n",
        "print('Most commonly occuring words and frequency\\n')\n",
        "words_freq = collections.Counter(all_words)\n",
        "words_freq.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTEzokotywof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu-TMB6LyIWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(all_words[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L0Y4Q6g2mte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove those words which are not contributing in analysis like star,phone,pro...\n",
        "words_remove = ['star','phone','pro','one','oneplus','plus','review']\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EfPy-NP9Y-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_words = [] \n",
        "  \n",
        "for w in all_words: \n",
        "    if w not in words_remove: \n",
        "        filtered_words.append(w) \n",
        "  \n",
        "print(all_words) \n",
        "print(filtered_words) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I4BgxDR9bB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Most commonly occuring words and frequency\\n')\n",
        "words_freq = collections.Counter(all_words)\n",
        "words_freq.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfTP6dD2KRqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq_word_df = pd.DataFrame(words_freq.most_common(15), columns=['Words','Freq'])\n",
        "freq_word_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USlpQGYaIYbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = []\n",
        "f_in = open(\"Amazon Reviews with Ratings.csv\",'r')\n",
        "for line in f_in.readlines():\n",
        "    text.append(line)\n",
        "f_in.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmSLGbosKeSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(15,10))\n",
        "freq_word_df.sort_values(by='Freq').plot.barh(x='Words', y = 'Freq', ax=ax, color = \"CRIMSON\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B1HkYBJKpaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "word_string= \" \".join(freq_word_df.Words)\n",
        "wordcloud = WordCloud(#stopwords = STOPWORDS,\n",
        "                          background_color='WHITE',\n",
        "                      max_words=20\n",
        "                         ).generate(word_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbO3JP6vKwYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15,20))\n",
        "plt.clf()\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tn5cdlIM05t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_text = [TextBlob(text) for text in corpus]\n",
        "print(sentiment_text[5].polarity)\n",
        "print(sentiment_text[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JX6Mq0AM0-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiments = [[text.sentiment.polarity, str(text)] for text in sentiment_text]\n",
        "sentiment_df = pd.DataFrame(sentiments, columns = [\"Polarity\", \"text\"])\n",
        "sentiment_df.sort_values(by= 'Polarity', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9TcEr6wM1DX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "#Plot the histogram of the polarity values\n",
        "sentiment_df.hist(bins=[-1,-0.75,-0.5,-0.25,0.25,0.5,0.75,1], ax=ax, color = '#2B2CBA')\n",
        "plt.title"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}